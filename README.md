# reminder λ°©λ²•λ΅ 
## Additional by μ—„νƒμ°

Visual Dialogue λ°μ΄ν„°μ…‹μ„ ν™μ©ν• Gemma-3 λ¨λΈ νμΈνλ‹ λ° ν‰κ°€ μ‹μ¤ν…μ— λ€ν•ν”„λ΅μ νΈμ…λ‹λ‹¤.

## π“ ν”„λ΅μ νΈ κ°μ”

λ³Έ ν”„λ΅μ νΈλ” VisDial λ°μ΄ν„°μ…‹μ„ ν™μ©ν•μ—¬ λ©€ν‹°λ¨λ‹¬ μ–Έμ–΄ λ¨λΈμΈ Gemma-3λ¥Ό μ‹κ°μ  λ€ν™”(Visual Dialogue)μ— νΉν™”μ‹ν‚¤κΈ° μ„ν• νμΈνλ‹ μ‹μ¤ν…μ„ μ κ³µν•©λ‹λ‹¤. λ¨λΈμ€ μ΄λ―Έμ§€λ¥Ό λ³΄κ³  μ‚¬μ©μμ™€μ λ€ν™”λ¥Ό ν†µν•΄ μ μ ν• μ‘λ‹µμ„ μƒμ„±ν•λ„λ΅ ν•™μµλ©λ‹λ‹¤.

## π“‚ ν”„λ΅μ νΈ κµ¬μ΅°

```
reminder_tag/
β”β”€β”€ README.md                    # κµμμμ© λ©”μΈ κ°€μ΄λ“
β”β”€β”€ requirements.txt             # μμ΅΄μ„± ν¨ν‚¤μ§€ λ©λ΅
β”β”€β”€ setup.py                     # ν¨ν‚¤μ§€ μ„¤μΉ μ¤ν¬λ¦½νΈ
β”β”€β”€ data/                        # λ°μ΄ν„° κ΄€λ ¨ νμΌ
β”‚   β”β”€β”€ README.md                # λ°μ΄ν„° μ„¤λ…μ„
β”‚   β””β”€β”€ download_data.py         # μλ™ λ‹¤μ΄λ΅λ“ μ¤ν¬λ¦½νΈ
β”β”€β”€ src/                         # μ†μ¤ μ½”λ“ λ¨λ“
β”‚   β”β”€β”€ data_generation/         # λ°μ΄ν„° μƒμ„± λ¨λ“
β”‚   β”‚   β”β”€β”€ __init__.py
β”‚   β”‚   β”β”€β”€ gen_base.py          # κΈ°λ³Έ λ°μ΄ν„° μƒμ„±
β”‚   β”‚   β”β”€β”€ gen_api.py           # API κΈ°λ° λ°μ΄ν„° μƒμ„±
β”‚   β”‚   β””β”€β”€ gen_eval.py          # ν‰κ°€ λ°μ΄ν„° μƒμ„±
β”‚   β”β”€β”€ training/                # νμΈνλ‹ λ¨λ“
β”‚   β”‚   β”β”€β”€ __init__.py
β”‚   β”‚   β””β”€β”€ finetune.py          # νμΈνλ‹ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ inference/               # μ¶”λ΅  λ¨λ“
β”‚   β”‚   β”β”€β”€ __init__.py
β”‚   β”‚   β””β”€β”€ inference.py         # λ¨λΈ μ¶”λ΅  μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ evaluation/              # ν‰κ°€ λ¨λ“
β”‚   β”‚   β”β”€β”€ __init__.py
β”‚   β”‚   β””β”€β”€ evaluation.py        # μ„±λ¥ ν‰κ°€ μ¤ν¬λ¦½νΈ
β”‚   β””β”€β”€ utils/                   # κ³µν†µ μ ν‹Έλ¦¬ν‹°
β”‚       β”β”€β”€ __init__.py
β”‚       β””β”€β”€ helpers.py           # κ³µν†µ ν•¨μ λ¨μ
β”β”€β”€ configs/                     # μ„¤μ • νμΌ
β”‚   β”β”€β”€ training_config.yaml     # ν›λ ¨ μ„¤μ •
β”‚   β””β”€β”€ evaluation_config.yaml   # ν‰κ°€ μ„¤μ •
β”β”€β”€ scripts/                     # μ‹¤ν–‰ μ¤ν¬λ¦½νΈ
β”‚   β”β”€β”€ run_pipeline.sh          # μ „μ²΄ νμ΄ν”„λΌμΈ μ‹¤ν–‰
β”‚   β””β”€β”€ quick_start.sh           # λΉ λ¥Έ μ‹μ‘ μ¤ν¬λ¦½νΈ
β”β”€β”€ notebooks/                   # κµμ΅μ© λ…ΈνΈλ¶
β”‚   β”β”€β”€ 01_data_exploration.ipynb
β”‚   β”β”€β”€ 02_model_finetuning.ipynb
β”‚   β””β”€β”€ 03_evaluation.ipynb
β””β”€β”€ tests/                       # λ‹¨μ„ ν…μ¤νΈ
    β””β”€β”€ test_evaluation.py
```

## π€ μ‹μ‘ν•κΈ°

### ν•„μ μ”κµ¬μ‚¬ν•­

- Python 3.9+
- CUDA μ§€μ› GPU (μµμ† 16GB μ΄μƒ VRAM κ¶μ¥)
- μµμ† 32GB RAM
- 200GB μ΄μƒμ μ €μ¥ κ³µκ°„ (λ°μ΄ν„°μ…‹ λ° λ¨λΈ ν¬ν•¨)

### λΉ λ¥Έ μ‹μ‘
```bash
bash quick_start.sh
```

### μ„¤μΉ λ°©λ²•

```bash
# 1. μ €μ¥μ† ν΄λ΅ 
git clone https://github.com/2025-1-nlp-intro-project/multimodal_memory.git
cd multimodal_memory/reminder_tag

# 2. κ°€μƒ ν™κ²½ μƒμ„± λ° ν™μ„±ν™”
conda create -n visdial python=3.10 -y
conda activate visdial

# 3. μμ΅΄μ„± μ„¤μΉ
pip install -r requirements.txt
```

### λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“

ν”„λ΅μ νΈμ—μ„ μ κ³µν•λ” μ¤ν¬λ¦½νΈλ¥Ό ν†µν•΄ Visual Dialogue λ°μ΄ν„°μ…‹κ³Ό COCO μ΄λ―Έμ§€λ¥Ό μλ™μΌλ΅ λ‹¤μ΄λ΅λ“ν•  μ μμµλ‹λ‹¤:

```bash
# λ°μ΄ν„°μ…‹ μλ™ λ‹¤μ΄λ΅λ“
python data/download_data.py

# νΉμ • λ¶„ν• λ§ λ‹¤μ΄λ΅λ“ (μ„ νƒμ )
python data/download_data.py --split train
python data/download_data.py --split val
```

## π’Ύ λ°μ΄ν„° μƒμ„±

λ¨λΈ ν›λ ¨μ— ν•„μ”ν• λ°μ΄ν„° μƒμ„± κ³Όμ •μ…λ‹λ‹¤.

### κΈ°λ³Έ λ°μ΄ν„° μƒμ„±

```bash
# κΈ°λ³Έ λ°μ΄ν„° μƒμ„± (Ollama μ‚¬μ©)
python -m src.data_generation.gen_base \
    --annotation_file data/visdial/annotations/instances_train2014.json \
    --visdial_path data/visdial/data/visdial_1.0_train.json \
    --output_path outputs/data_base.json \
    --max_samples 1000

# μ¶”λ΅  κ³Όμ • ν¬ν•¨ λ°μ΄ν„° μƒμ„±
python -m src.data_generation.gen_api \
    --annotation_file data/visdial/annotations/instances_train2014.json \
    --visdial_path data/visdial/data/visdial_1.0_train.json \
    --output_path outputs/data_api.json \
    --export_training outputs/training_data.json \
    --max_samples 1000
```

### ν‰κ°€ λ°μ΄ν„° μƒμ„±

λ¨λΈ ν‰κ°€λ¥Ό μ„ν• λ°μ΄ν„°μ…‹ μƒμ„±:

```bash
# ν‰κ°€ λ°μ΄ν„° μƒμ„±
python -m src.data_generation.gen_eval \
    --visdial_path data/visdial/data/visdial_1.0_val.json \
    --image_dir data/visdial/images/val2018/ \
    --output_path outputs/eval_data.json \
    --export_predictions outputs/predictions.json \
    --max_samples 500

# ν‰κ°€ μ§€ν‘ κ³„μ‚°
python src/evaluation/evaluate.py \
    --generated outputs/predictions.json \
    --ground_truth data/visdial/data/visdial_1.0_val.json \
    --output outputs/evaluation_results.json
```

## π”§ λ¨λΈ νμΈνλ‹

λ¨λΈ νμΈνλ‹μ€ λ‹¤μ λ…λ Ήμ–΄λ΅ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤:

```bash
# κΈ°λ³Έ μ„¤μ •μΌλ΅ νμΈνλ‹
python src/training/finetune.py --config configs/training_config.yaml

# κ³ κΈ‰ μ„¤μ •μΌλ΅ νμΈνλ‹
python src/training/finetune.py \
  --model_name "unsloth/gemma-3-4b-it" \
  --dataset_path data/generated/api_dataset.json \
  --output_dir outputs/gemma3_finetune \
  --batch_size 2 \
  --grad_accum 4 \
  --lr 1e-5 \
  --epochs 3
```

### νμΈνλ‹ μ„¤μ • μµμ…

`configs/training_config.yaml`μ—μ„ λ‹¤μκ³Ό κ°™μ€ μ„¤μ •μ„ μ΅°μ •ν•  μ μμµλ‹λ‹¤:

```yaml
# λ¨λΈ μ„¤μ •
model:
  name: "unsloth/gemma-3-4b-it"
  load_in_4bit: true
  use_gradient_checkpointing: "unsloth"

# PEFT μ„¤μ •
peft:
  finetune_vision_layers: true
  finetune_language_layers: true
  finetune_attention_modules: true
  finetune_mlp_modules: true
  r: 16
  lora_alpha: 16
  lora_dropout: 0
  bias: "none"
  use_rslora: false

# ν›λ ¨ μ„¤μ •
training:
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  warmup_steps: 5
  learning_rate: 1e-5
  fp16: false
  bf16: true
  logging_steps: 1
  optim: "adamw_8bit"
  weight_decay: 0.01
  lr_scheduler_type: "linear"
  max_seq_length: 2048
  output_dir: "outputs"
```

## π” μ¶”λ΅  μ‹¤ν–‰

νμΈνλ‹λ λ¨λΈμ„ μ‚¬μ©ν•μ—¬ μ¶”λ΅ μ„ μ‹¤ν–‰ν•λ” λ°©λ²•:

```bash
# κΈ°λ³Έ μ¶”λ΅ 
python src/inference/inference.py \
  --model_path outputs/gemma3_finetune \
  --image_path path/to/image.jpg \
  --conversation "Q: What do you see in this image?\nA: I see children playing on the beach.\nQ: How many children are there?"

# λ°°μΉ μ¶”λ΅ 
python src/inference/inference.py \
  --model_path outputs/gemma3_finetune \
  --batch_file data/test_batch.json \
  --output_file results/batch_results.json
```

## π“ ν‰κ°€ μ‹¤ν–‰

λ¨λΈ μ„±λ¥ ν‰κ°€λ¥Ό μ„ν• μ¤ν¬λ¦½νΈ μ‹¤ν–‰:

```bash
# κΈ°λ³Έ ν‰κ°€
python src/evaluation/evaluation.py \
  --prediction_file results/batch_results.json \
  --groundtruth_file data/visdial/data/visdial_1.0_val.json

# μƒμ„Έ ν‰κ°€ μ§€ν‘ μ¶λ ¥
python src/evaluation/evaluation.py \
  --prediction_file results/batch_results.json \
  --groundtruth_file data/visdial/data/visdial_1.0_val.json \
  --verbose
```

### ν‰κ°€ μ§€ν‘ (Evaluation Metrics)

Visual Dialogue νμΈνλ‹ ν”„λ΅μ νΈλ” **BERTScoreλ¥Ό μ£Όμ” λ©”νΈλ¦­**μΌλ΅ μ‚¬μ©ν•λ©°, λ³΄μ΅° λ©”νΈλ¦­λ“¤κ³Ό ν•¨κ» ν¬κ΄„μ μΈ ν‰κ°€λ¥Ό μ κ³µν•©λ‹λ‹¤.

**π― μ£Όμ” λ©”νΈλ¦­: BERTScore**

#### BERTScoreλ€?

BERTScoreλ” BERTμ μ‚¬μ „ ν›λ ¨λ μ»¨ν…μ¤μ¶”μ–Ό μ„λ² λ”©μ„ ν™μ©ν•μ—¬ ν…μ¤νΈ κ°„ μλ―Έμ  μ μ‚¬μ„±μ„ μΈ΅μ •ν•λ” νμ‹ μ μΈ ν‰κ°€ μ§€ν‘μ…λ‹λ‹¤. κΈ°μ΅΄μ n-gram κΈ°λ° λ©”νΈλ¦­λ“¤(BLEU, ROUGE)κ³Ό λ‹¬λ¦¬, **λ‹¨μν• λ‹¨μ–΄ λ§¤μΉ­μ„ λ„μ–΄μ„ μ‹¤μ  μλ―Έλ¥Ό μ΄ν•΄**ν•©λ‹λ‹¤.

#### μ™ BERTScoreμΈκ°€?

π” κΈ°μ΅΄ λ©”νΈλ¦­μ ν•κ³„
```
μ°Έμ΅° λ‹µλ³€: "The food was delicious."
μƒμ„± λ‹µλ³€: "I loved the meal."
```

- **BLEU/ROUGE**: λ‹¨μ–΄κ°€ λ‹¬λΌμ„ λ‚®μ€ μ μ (0.0)
- **BERTScore**: μλ―Έκ°€ μ μ‚¬ν•λ―€λ΅ λ†’μ€ μ μ (0.85+)

β¨ BERTScoreμ μ¥μ 

1. **μλ―Έμ  μ΄ν•΄**: λ™μμ–΄, ν¨λ¬ν”„λ μ΄μ¦λ¥Ό μ¬λ°”λ¥΄κ² μΈμ‹
2. **μ»¨ν…μ¤νΈ κ³ λ ¤**: λ¬Έμ¥ λ‚΄ λ‹¨μ–΄μ λ¬Έλ§¥μ  μλ―Έ νμ•…
3. **μ μ—°ν• ν‰κ°€**: λ‹¤μ–‘ν• ν‘ν„ λ°©μ‹μ„ κ³µμ •ν•κ² ν‰κ°€
4. **μΈκ°„ ν‰κ°€μ™€ λ†’μ€ μƒκ΄€κ΄€κ³„**: μ‹¤μ  μΈκ°„μ νλ‹¨κ³Ό λ§¤μ° μ μ‚¬

## π§ μ „μ²΄ νμ΄ν”„λΌμΈ μ‹¤ν–‰

λ‹¨μΌ λ…λ ΉμΌλ΅ μ „μ²΄ νμ΄ν”„λΌμΈ(λ°μ΄ν„° μƒμ„±, ν›λ ¨, ν‰κ°€)μ„ μ‹¤ν–‰ν•  μ μμµλ‹λ‹¤:

```bash
# μ „μ²΄ νμ΄ν”„λΌμΈ μ‹¤ν–‰
./scripts/run_pipeline.sh

# κ³ κΈ‰ μ„¤μ •μΌλ΅ μ‹¤ν–‰
./scripts/run_pipeline.sh --config configs/custom_config.yaml --output experiment_1
```
# Extraction-Memorization-Retrieval

## Additional by μ΄κ°•μ±

### MA-LMM with ImageBind: Multimodal Memory & Dialogue System

#### 1. ν”„λ΅μ νΈ κ°μ” (Overview)
λ³Έ ν”„λ΅μ νΈλ” Vision, Audio λ“± λ‹¤μ–‘ν• λ¨λ‹¬λ¦¬ν‹°λ¥Ό ν•λ‚μ μ„λ² λ”© κ³µκ°„μ— κ²°ν•©ν•λ” ImageBind λ¨λΈμ„ κΈ°λ°μΌλ΅, μ¥κΈ° κΈ°μ–µ λ° μ¶”λ΅  λ¥λ ¥μ„ κ°–μ¶ λ©€ν‹°λ¨λ‹¬ κΈ°μ–µ μ‹μ¤ν…μ„ κ°λ°ν•λ” κ²ƒμ„ λ©ν‘λ΅ ν•©λ‹λ‹¤.  
κΈ°μ΅΄ λ€ν•μ–Έμ–΄λ¨λΈ(LLM)μ ν•κ³„μΈ μ¥κΈ° κΈ°μ–µ λ¶€μ΅±κ³Ό μ¶”λ΅  μ¤λ¥λ¥Ό κ·Ήλ³µν•κΈ° μ„ν•΄, **MA-LMM (Memory-Augmented Large Multimodal Model)**μ μ•„ν‚¤ν…μ²λ¥Ό μ°¨μ©ν•κ³ , μ—¬κΈ°μ— ImageBindμ κ°•λ ¥ν• λ©€ν‹°λ¨λ‹¬ μΈμ½”λ”© λ¥λ ¥μ„ κ²°ν•©ν–μµλ‹λ‹¤.

#### 2. μµμΆ… λ¨λΈ μ•„ν‚¤ν…μ²
λ³Έ ν”„λ΅μ νΈμ—μ„ κµ¬ν„λ λ¨λΈμ€ λ‹¤μκ³Ό κ°™μ€ λ…μμ μΈ νμ΄ν”„λΌμΈ μ•„ν‚¤ν…μ²λ¥Ό κ°€μ§‘λ‹λ‹¤.

##### μ…λ ¥ μΈμ½”λ” (Frozen)
- **Image Encoder**: ImageBind-Hugeμ Vision Encoder (μ¶λ ¥: 1024μ°¨μ›)  
- **Text Encoder**: ImageBind-Hugeμ Text Encoder (μ¶λ ¥: 1024μ°¨μ›)

##### μ—°κ²° λ¨λ“ (Trainable)
- **FC Layer (imagebind_fc)**: ImageBindμ Vision, Text μ„λ² λ”©μ„ κ²°ν•©ν• 2048μ°¨μ› λ²΅ν„°λ¥Ό λ°›μ•„, Q-Formerκ°€ μ²λ¦¬ν•  μ μλ” 1024μ°¨μ› λ²΅ν„°λ΅ λ³€ν™ν•λ” `nn.Linear(2048, 1024)` λ μ΄μ–΄  
- **μμ„ μ„λ² λ”© (turn_pe)**: Visual Dialogμ ν„΄(turn) μμ„ μ •λ³΄(0~10)λ¥Ό ν•™μµν•κΈ° μ„ν• `nn.Embedding(11, 1024)` λ μ΄μ–΄

##### λΈλ¦Ώμ§€ λ¨λ“ (Frozen)
- **Q-Former**: Vision νΉμ§•κ³Ό μ–Έμ–΄(μ§λ¬Έ)λ¥Ό μ—°κ²°ν•λ” ν•µμ‹¬ λ¨λ“. μ…λ ¥μΌλ΅ 1024μ°¨μ›μ νΉμ§• λ²΅ν„°λ¥Ό λ°›λ„λ΅ hidden_size=1024λ΅ μ„¤μ •  
- **μ–Έμ–΄ μƒμ„± λ¨λ“ (Frozen)**  
  - **Projection Layer (llm_proj)**: Q-Formerμ μ¶λ ¥(1024μ°¨μ›)μ„ LLMμ μ…λ ¥ μ°¨μ›(2048μ°¨μ›)μΌλ΅ λ³€ν™ν•λ” `nn.Linear(1024, 2048)` λ μ΄μ–΄  
  - **LLM**: Llama-3.2-1B λ¨λΈμ„ bitsandbytesλ¥Ό ν†µν•΄ 4-bit μ–‘μν™”ν•μ—¬ λ΅λ“

#### 3. ν•™μµ νμ΄ν”„λΌμΈ
ImageBindμ™€ MA-LMMμ λΌμ΄λΈλ¬λ¦¬ μμ΅΄μ„± μ¶©λ(PyTorch, timm λ²„μ „ λ“±)μ„ ν•΄κ²°ν•κΈ° μ„ν•΄, κ°μμ μ—­ν• μ„ λ…λ¦½λ κ°€μƒν™κ²½μ—μ„ μν–‰ν•λ” 2λ‹¨κ³„ νμ΄ν”„λΌμΈ λ°©μ‹μ„ μ±„νƒν–μµλ‹λ‹¤.

##### 1λ‹¨κ³„: μ„λ² λ”© μ‚¬μ „ μ¶”μ¶ (in imagebind_env)
ImageBind μ „μ© κ°€μƒν™κ²½μ—μ„, VisDial v1.0 λ°μ΄ν„°μ…‹μ λ¨λ“  μ΄λ―Έμ§€μ™€ κ° λ€ν™” ν„΄μ μ§λ¬Έ ν…μ¤νΈμ— λ€ν• Vision/Text μ„λ² λ”©μ„ λ―Έλ¦¬ μ¶”μ¶ν•μ—¬ λ””μ¤ν¬μ— `.pt` νμΌλ΅ μ €μ¥ν•©λ‹λ‹¤.

##### 2λ‹¨κ³„: λ¨λΈ νμΈνλ‹ (in malmm env)
MA-LMM ν•™μµμ© κ°€μƒν™κ²½μ—μ„, μ‚¬μ „ μ¶”μ¶λ μ„λ² λ”©μ„ μ…λ ¥μΌλ΅ λ°›μ•„ μ¤μ§ `imagebind_fc`μ™€ `turn_pe` λ μ΄μ–΄λ§ ν•™μµμ‹ν‚µλ‹λ‹¤.

#### 4. μ„¤μΉ λ° μ‹¤ν–‰ κ°€μ΄λ“

##### 4.1 ν™κ²½ μ„¤μ •

###### imagebind_env μƒμ„± (μ„λ² λ”© μ¶”μ¶μ©)
```bash
conda env create -f environment_imagebind.yml
conda activate imagebind_env
```

###### malmm_env μƒμ„± (λ¨λΈ νμΈνλ‹μ©)

```bash
conda env create -f environment_malmm.yml
conda activate malmm
```

μ°Έκ³ : environment_*.yml νμΌμ€ conda env export > [νμΌμ΄λ¦„].yml λ…λ Ήμ–΄λ΅ μƒμ„±ν•  μ μμµλ‹λ‹¤.

##### 4.2 λ°μ΄ν„° μ¤€λΉ„ λ° μ‹¤ν–‰

β€Ά	λ°μ΄ν„°μ…‹ λ‹¤μ΄λ΅λ“
lavis/datasets/visdial/ ν΄λ”μ— VisDial v1.0 μ–΄λ…Έν…μ΄μ…κ³Ό MS COCO 2014, VisualDialog_val2018 μ΄λ―Έμ§€λ¥Ό λ‹¤μ΄λ΅λ“ν• ν›„ μ••μ¶• ν•΄μ 
β€Ά	μ„λ² λ”© μ¶”μ¶
```bash
conda activate imagebind_env
python extract_visdial_embeddings.py
```
β€Ά	λ¨λΈ νμΈνλ‹
```bash
conda activate malmm
cd MA-LMM
python -m lavis.tasks.run β€“cfg-path lavis/configs/tasks/finetune_visdial.yaml
```
β€Ά	μ„±λ¥ ν‰κ°€
```bash
python evaluate.py \
β€“checkpoint β€lavis/output/finetune_visdial/finetune_visdial/checkpoint_latest.pthβ€ \
β€“llm_model_path β€llm/llama-3.2-1B/Llama-3.2-1Bβ€
```
-- checkpoint μ—, μ„±λ¥μ„ ν‰κ°€ν•κ³ μ μ²΄ν¬ν¬μΈνΈ κ²½λ΅λ¥Ό μ μ ν μ§€μ •ν•©λ‹λ‹¤. 
! μ£Όμν•  μ μ€, cc3m datasetμ κ²½μ° lavis/models/../blip2.pyμ, 208 lineμ 
```bash
encoder_config.hidden_size = 1024 # 768 -> νμΈνλ‹ μ΄μ „ κ²°κ³Όλ¥Ό μ„ν•΄μ„, 768μΌλ΅ λλ ¤μ•Ό ν•¨.
```

#### 5. μ‹¤ν— κ²°κ³Ό

λ¨λΈ	BLEU-4 Score
νμΈνλ‹ μ „ (FC Layerλ§ ν•™μµ)	14.96
νμΈνλ‹ ν›„ (VisDialλ΅ FC+PE ν•™μµ)	24.80

λ¶„μ„: VisDial λ°μ΄ν„°μ…‹κ³Ό μμ„ μ„λ² λ”©μ„ μ΄μ©ν• νμΈνλ‹μ„ ν†µν•΄ BLEU-4 μ μκ°€ μ•½ 65.8% ν–¥μƒλμ—μµλ‹λ‹¤.

#### 6. ν–¥ν›„ κ³Όμ  (Future Work)
  β€Ά	Retrieval λ΅μ§ κµ¬ν„: Recency, Frequency, Saliency κΈ°λ° μ¤μ½”μ–΄λ§ ν•¨μλ¥Ό κµ¬ν„ν•μ—¬ λ€ν™” λ§¥λ½μ— λ§λ” κ³Όκ±° κΈ°μ–µμ„ λ™μ μΌλ΅ κ²€μƒ‰ν•λ” λ¨λ“ μ¶”κ°€
  β€Ά	Self-Reflection μ μ©: κ²€μƒ‰λ κΈ°μ–µμ„ <reminder> νƒκ·Έλ΅ ν”„λ΅¬ν”„νΈμ— μ£Όμ…ν•κ³ , λ¨λΈμ΄ μ—°μ‡„μ  μ‚¬κ³ (CoT)λ¥Ό ν†µν•΄ λ” λ…Όλ¦¬μ μΈ λ‹µλ³€ μƒμ„±
  β€Ά	μΆ…ν•© ν‰κ°€: VisDialλΏλ§ μ•„λ‹λΌ ScienceQA λ“± λ‹¤μ–‘ν• λ²¤μΉλ§ν¬ λ°μ΄ν„°μ…‹μΌλ΅ μ •λ‰Β·μ •μ„± ν‰κ°€ μν–‰
